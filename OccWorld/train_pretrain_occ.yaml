# ===== model =====
model_name_or_path: /home/vlm_driving/.cache/huggingface/hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/cc594898137f460bfe9f0759e9844b3ce807cfb5
resize_vocab: true
# 如需额外新词，用 add_tokens 而不是单独的 tokenizer 目录
# add_tokens: <OCC_A>,<OCC_B>

# ===== data =====
dataset: occ_sharegpt
dataset_dir: /nas/vlm_driving/fsdrive-occworld/OccWorld/data
template: qwen2_vl
cutoff_len: 2048
packing: false
train_on_prompt: false

# ===== train =====
output_dir: ./output_occ_lora
per_device_train_batch_size: 1
gradient_accumulation_steps: 16
learning_rate: 1.5e-4
optim: adamw_torch
weight_decay: 0.05
num_train_epochs: 1
warmup_ratio: 0.03
lr_scheduler_type: cosine
bf16: true
logging_steps: 10
save_steps: 200
save_total_limit: 2

# ===== lora =====
finetuning_type: lora
lora_target: q_proj,k_proj,v_proj,o_proj,gate_proj,up_proj,down_proj
lora_rank: 16
lora_alpha: 32
lora_dropout: 0.05
use_rslora: true
